{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Diane/Desktop/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "pal = sns.color_palette()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>How does the Surface Pro himself 4 compare wit...</td>\n",
       "      <td>Why did Microsoft choose core m3 and not core ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Should I have a hair transplant at age 24? How...</td>\n",
       "      <td>How much cost does hair transplant require?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>What but is the best way to send money from Ch...</td>\n",
       "      <td>What you send money to China?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Which food not emulsifiers?</td>\n",
       "      <td>What foods fibre?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>How \"aberystwyth\" start reading?</td>\n",
       "      <td>How their can I start reading?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id                                          question1  \\\n",
       "0        0  How does the Surface Pro himself 4 compare wit...   \n",
       "1        1  Should I have a hair transplant at age 24? How...   \n",
       "2        2  What but is the best way to send money from Ch...   \n",
       "3        3                        Which food not emulsifiers?   \n",
       "4        4                   How \"aberystwyth\" start reading?   \n",
       "\n",
       "                                           question2  \n",
       "0  Why did Microsoft choose core m3 and not core ...  \n",
       "1        How much cost does hair transplant require?  \n",
       "2                      What you send money to China?  \n",
       "3                                  What foods fibre?  \n",
       "4                     How their can I start reading?  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_data, validation_data = train_test_split(train, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_vocab(datasets):\n",
    "  vocab = dict()\n",
    "  \n",
    "  for text in datasets: \n",
    "    text = text.lower().split()\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    text = [w for w in text if not w in stops]\n",
    "    text = \" \".join(text)\n",
    "    \n",
    "    text = re.sub(\"[^\\w]\", \" \",  text)\n",
    "#     text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "   \n",
    "    text = text.split()\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    stemmed_words = [stemmer.stem(word) for word in text]\n",
    "    \n",
    "    for word in text:\n",
    "        if word not in vocab:\n",
    "            vocab[word] = len(vocab)\n",
    "\n",
    "  print('Vocab size: {}'.format(len(vocab)))\n",
    "\n",
    "  return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_vocab1(datasets):\n",
    "  vocab = dict()\n",
    "  \n",
    "  for data in datasets:\n",
    "        wordList = re.sub(\"[^\\w]\", \" \",  data).lower().split()\n",
    "#         wordList = [word for word in wordList if word not in stopwords.words('english')]\n",
    "        for word in wordList:\n",
    "            word = stemmer.stem(word)\n",
    "            if word not in vocab and word not in stopwords.words('english'):\n",
    "                vocab[word] = len(vocab)\n",
    "\n",
    "  print('Vocab size: {}'.format(len(vocab)))\n",
    "\n",
    "  return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 77597\n"
     ]
    }
   ],
   "source": [
    "total_vocab = build_vocab(np.append(train_data.question1, train_data.question2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 58473\n"
     ]
    }
   ],
   "source": [
    "total_vocab1 = build_vocab1(np.append(train_data.question1, train_data.question2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rebalance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_match_share(row):\n",
    "    q1words = {}\n",
    "    q2words = {}\n",
    "    for word in re.sub(\"[^\\w]\", \" \",  row['question1']).lower().split():\n",
    "#     for word in str(row['question1']).lower().split():\n",
    "        word = stemmer.stem(word)\n",
    "        if word not in stopwords.words('english'):\n",
    "            q1words[word] = 1\n",
    "    for word in re.sub(\"[^\\w]\", \" \",  row['question2']).lower().split():\n",
    "#     for word in str(row['question2']).lower().split():\n",
    "        word = stemmer.stem(word)\n",
    "        if word not in stopwords.words('english'):\n",
    "            q2words[word] = 1\n",
    "    if len(q1words) == 0 or len(q2words) == 0:\n",
    "        return 0\n",
    "    shared_words_in_q1 = [w for w in q1words.keys() if w in q2words]\n",
    "    shared_words_in_q2 = [w for w in q2words.keys() if w in q1words]\n",
    "    R = float(len(shared_words_in_q1) + len(shared_words_in_q2))/(len(q1words) + len(q2words))\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Diane/Desktop/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:6: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "/Users/Diane/Desktop/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:10: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n"
     ]
    }
   ],
   "source": [
    "train_word_match = train.apply(word_match_share, axis=1, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_word_match1 = train.apply(word_match_share, axis=1, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train = pd.DataFrame()\n",
    "x_test = pd.DataFrame()\n",
    "x_train['word_match'] = train_word_match\n",
    "# x_test['word_match'] = test.apply(word_match_share, axis=1, raw=True)\n",
    "y_train = train['is_duplicate'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_train = x_train[y_train == 1]\n",
    "neg_train = x_train[y_train == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19124341597\n"
     ]
    }
   ],
   "source": [
    "# reference from https://www.kaggle.com/anokas/data-analysis-xgboost-starter-0-35460-lb\n",
    "\n",
    "p = 0.165\n",
    "scale = ((len(pos_train) / float(len(pos_train) + len(neg_train))) / p) - 1\n",
    "while scale > 1:\n",
    "    neg_train = pd.concat([neg_train, neg_train])\n",
    "    scale -=1\n",
    "neg_train = pd.concat([neg_train, neg_train[:int(scale * len(neg_train))]])\n",
    "print(len(pos_train) / float(len(pos_train) + len(neg_train)))\n",
    "\n",
    "x_train = pd.concat([pos_train, neg_train])\n",
    "y_train = (np.zeros(len(pos_train)) + 1).tolist() + np.zeros(len(neg_train)).tolist()\n",
    "del pos_train, neg_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.683169\tvalid-logloss:0.683231\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "[10]\ttrain-logloss:0.60184\tvalid-logloss:0.602426\n",
      "[20]\ttrain-logloss:0.54452\tvalid-logloss:0.545512\n",
      "[30]\ttrain-logloss:0.502731\tvalid-logloss:0.504048\n",
      "[40]\ttrain-logloss:0.471566\tvalid-logloss:0.473149\n",
      "[50]\ttrain-logloss:0.447946\tvalid-logloss:0.44975\n",
      "[60]\ttrain-logloss:0.429706\tvalid-logloss:0.431711\n",
      "[70]\ttrain-logloss:0.415598\tvalid-logloss:0.417775\n",
      "[80]\ttrain-logloss:0.404598\tvalid-logloss:0.406922\n",
      "[90]\ttrain-logloss:0.395972\tvalid-logloss:0.398417\n",
      "[100]\ttrain-logloss:0.389181\tvalid-logloss:0.391734\n",
      "[110]\ttrain-logloss:0.383827\tvalid-logloss:0.386483\n",
      "[120]\ttrain-logloss:0.379595\tvalid-logloss:0.382339\n",
      "[130]\ttrain-logloss:0.376243\tvalid-logloss:0.379063\n",
      "[140]\ttrain-logloss:0.373561\tvalid-logloss:0.376451\n",
      "[150]\ttrain-logloss:0.371418\tvalid-logloss:0.374374\n",
      "[160]\ttrain-logloss:0.369707\tvalid-logloss:0.372723\n",
      "[170]\ttrain-logloss:0.368347\tvalid-logloss:0.371415\n",
      "[180]\ttrain-logloss:0.367266\tvalid-logloss:0.370378\n",
      "[190]\ttrain-logloss:0.366398\tvalid-logloss:0.36955\n",
      "[200]\ttrain-logloss:0.365708\tvalid-logloss:0.368891\n",
      "[210]\ttrain-logloss:0.365155\tvalid-logloss:0.368367\n",
      "[220]\ttrain-logloss:0.364715\tvalid-logloss:0.367952\n",
      "[230]\ttrain-logloss:0.364363\tvalid-logloss:0.367622\n",
      "[240]\ttrain-logloss:0.364079\tvalid-logloss:0.367357\n",
      "[250]\ttrain-logloss:0.363852\tvalid-logloss:0.367149\n",
      "[260]\ttrain-logloss:0.363669\tvalid-logloss:0.366987\n",
      "[270]\ttrain-logloss:0.363524\tvalid-logloss:0.36686\n",
      "[280]\ttrain-logloss:0.363405\tvalid-logloss:0.366757\n",
      "[290]\ttrain-logloss:0.363305\tvalid-logloss:0.366671\n",
      "[300]\ttrain-logloss:0.363213\tvalid-logloss:0.366594\n",
      "[310]\ttrain-logloss:0.363138\tvalid-logloss:0.366531\n",
      "[320]\ttrain-logloss:0.363076\tvalid-logloss:0.366479\n",
      "[330]\ttrain-logloss:0.363035\tvalid-logloss:0.366452\n",
      "[340]\ttrain-logloss:0.363008\tvalid-logloss:0.366433\n",
      "[350]\ttrain-logloss:0.362977\tvalid-logloss:0.366411\n",
      "[360]\ttrain-logloss:0.36295\tvalid-logloss:0.366389\n",
      "[370]\ttrain-logloss:0.362922\tvalid-logloss:0.366366\n",
      "[380]\ttrain-logloss:0.362901\tvalid-logloss:0.366352\n",
      "[390]\ttrain-logloss:0.362869\tvalid-logloss:0.366327\n",
      "[399]\ttrain-logloss:0.362845\tvalid-logloss:0.366309\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "params = {}\n",
    "params['objective'] = 'binary:logistic'\n",
    "params['eval_metric'] = 'logloss'\n",
    "params['eta'] = 0.02\n",
    "params['max_depth'] = 6\n",
    "\n",
    "d_train = xgb.DMatrix(x_train, label=y_train)\n",
    "d_valid = xgb.DMatrix(x_valid, label=y_valid)\n",
    "\n",
    "watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "\n",
    "bst = xgb.train(params, d_train, 400, watchlist, early_stopping_rounds=50, verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_val = xgb.DMatrix(x_valid)\n",
    "p_val = bst.predict(d_val)\n",
    "\n",
    "# val = pd.DataFrame(index = x_valid.index)\n",
    "# val['is_duplicate'] = p_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(p_val)):\n",
    "    if p_val[i] >= 0.5:\n",
    "        p_val[i] = 1\n",
    "    else: \n",
    "        p_val[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "for i in range(len(p_val)):\n",
    "    if p_val[i] == y_valid[i]:\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8122013094338172"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(count)/len(p_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_sentence(sent):\n",
    "    sentence = re.sub(\"[^\\w]\", \" \",  sent).lower().split()\n",
    "\n",
    "    for word in sentence:\n",
    "#         word = stemmer.stem(word)\n",
    "        if word in stopwords.words('english'):\n",
    "            sentence.remove(word)\n",
    "\n",
    "    sentence = \" \".join(sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cosine(v1, v2):\n",
    "    \n",
    "    v1 = np.array(v1)\n",
    "    v2 = np.array(v2)\n",
    "\n",
    "    return np.dot(v1, v2) / (np.sqrt(np.sum(v1**2)) * np.sqrt(np.sum(v2**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Diane/Desktop/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "for col in ['question1', 'question2']:\n",
    "    train_data[col] = train_data[col].apply(clean_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323429\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>286569</th>\n",
       "      <td>286569</td>\n",
       "      <td>324559</td>\n",
       "      <td>190333</td>\n",
       "      <td>does linkedin let see viewed profile</td>\n",
       "      <td>facebook ever offer feature like linkedin wher...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291655</th>\n",
       "      <td>291655</td>\n",
       "      <td>19999</td>\n",
       "      <td>68878</td>\n",
       "      <td>people 99 be allowed vote</td>\n",
       "      <td>people 97 be allowed vote</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139515</th>\n",
       "      <td>139515</td>\n",
       "      <td>102850</td>\n",
       "      <td>221939</td>\n",
       "      <td>is best way write cv</td>\n",
       "      <td>can write cv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56117</th>\n",
       "      <td>56117</td>\n",
       "      <td>98814</td>\n",
       "      <td>98815</td>\n",
       "      <td>is shah rukh khan real life</td>\n",
       "      <td>shah rukh khan real life what is it like inter...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73504</th>\n",
       "      <td>73504</td>\n",
       "      <td>126130</td>\n",
       "      <td>126131</td>\n",
       "      <td>makes leader</td>\n",
       "      <td>makes leader leader</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2                             question1  \\\n",
       "286569  286569  324559  190333  does linkedin let see viewed profile   \n",
       "291655  291655   19999   68878             people 99 be allowed vote   \n",
       "139515  139515  102850  221939                  is best way write cv   \n",
       "56117    56117   98814   98815           is shah rukh khan real life   \n",
       "73504    73504  126130  126131                          makes leader   \n",
       "\n",
       "                                                question2  is_duplicate  \n",
       "286569  facebook ever offer feature like linkedin wher...             0  \n",
       "291655                          people 97 be allowed vote             1  \n",
       "139515                                       can write cv             1  \n",
       "56117   shah rukh khan real life what is it like inter...             1  \n",
       "73504                                 makes leader leader             1  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print len(train_data)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_questions = train_data['question1'].append(train_data['question2'], ignore_index=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    does linkedin let see viewed profile\n",
       "1               people 99 be allowed vote\n",
       "2                    is best way write cv\n",
       "3             is shah rukh khan real life\n",
       "4                            makes leader\n",
       "dtype: object"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_questions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
